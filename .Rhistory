labs(y = 'Disagreement', x = 'Difference in beliefs') +
scale_fill_brewer(palette = 'Dark2') +
#facet_wrap(~ importance_binarized) +
ggtitle('Actual data')
disagreement_figure
data = subset(data, select=-c(disagreement))
#data = subset(data, select=-c(disagreement))
colnames(data)[colnames(data=='.prediction')] = 'disagreement'
#data = subset(data, select=-c(disagreement))
rename(data, '.prediction' = 'disagreement')
#data = subset(data, select=-c(disagreement))
rename(data, 'disagreement' = '.prediction')
#data = subset(data, select=-c(disagreement))
data = rename(data, 'disagreement' = '.prediction')
write.csv(data, 'ord_bet_reg_data.csv')
# read in the data
data = read.csv(file = 'ord_bet_reg_data.csv')
# make a simple plot the depicts what we are interested in
disagreement_figure = ggplot(data, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3, color='pink') +
labs(y = 'Disagreement', x = 'Difference in beliefs') +
scale_fill_brewer(palette = 'Dark2') +
#facet_wrap(~ importance_binarized) +
ggtitle('Actual data')
disagreement_figure
# read in the data
data = read.csv(file = 'ord_bet_reg_data.csv')
# make a simple plot the depicts what we are interested in
disagreement_figure = ggplot(data, aes(x=divergence, y=disagreement)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3, color='pink') +
labs(y = 'Disagreement', x = 'Difference in beliefs') +
scale_fill_brewer(palette = 'Dark2') +
#facet_wrap(~ importance_binarized) +
ggtitle('Actual data')
disagreement_figure
# linear model
output = capture.output(linear_model <- brm(
formula = disagreement ~ divergence + change + confidence + importance + belief_strength + same_side,
data = data,
chains = 6, iter = 3000, warmup = 2000,
cores = 6, seed = 1234,
backend = "cmdstanr"
))
# we can add the `loo` criterion for model fitting later
linear_model = add_criterion(linear_model, 'loo',"waic")
plot(linear_model)
kable(tidy(linear_model))
# check the Rhat values
kable(diagnostic_posterior(linear_model), digits=3)
pp_check(linear_model)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
linear_predictions = predicted_draws(linear_model, newdata=data)
data = subset(data, select=-c(.row,.chain,.iteration,.draw,X.1,X.2))
#data = rename(data, 'disagreement' = '.prediction')
write.csv(data, 'ord_bet_reg_data.csv')
data = subset(data, select=-c(X))
#data = rename(data, 'disagreement' = '.prediction')
write.csv(data, 'ord_bet_reg_data.csv')
# read in the data
data = read.csv(file = 'ord_bet_reg_data.csv')
# make a simple plot the depicts what we are interested in
disagreement_figure = ggplot(data, aes(x=divergence, y=disagreement)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3, color='pink') +
labs(y = 'Disagreement', x = 'Difference in beliefs') +
scale_fill_brewer(palette = 'Dark2') +
#facet_wrap(~ importance_binarized) +
ggtitle('Actual data')
disagreement_figure
# generate a data frame of new predicted values from the data that we already have. does it even do well?
linear_predictions = predicted_draws(linear_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
linear_predictions_subset = linear_predictions[sample(nrow(linear_predictions),10000),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
linear_predict_plot = ggplot(linear_predictions_subset, aes(x=divergence, y=.prediction, color="red")) +
theme_classic(base_size = 15) +
geom_point(alpha=0.3, size=3) +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from linear model')
linear_predict_plot
# generate a data frame of new predicted values from the data that we already have. does it even do well?
linear_predictions = predicted_draws(linear_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
linear_predictions_subset = linear_predictions[sample(nrow(linear_predictions),10000),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
linear_predict_plot = ggplot(linear_predictions_subset, aes(x=divergence, y=.prediction, color="red")) +
theme_classic(base_size = 15) +
geom_point(alpha=0.1, size=3) +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from linear model')
linear_predict_plot
disagreement_figure
par(mrrow=c(1,2))
disagreement_figure
linear_predict_plot
par(mfrow=c(1,2))
disagreement_figure
linear_predict_plot
library(gridExtra)
grid.arrange(disagreement_figure, linear_predict_plot)
library(gridExtra)
grid.arrange(disagreement_figure, linear_predict_plot)
library(gridExtra)
grid.arrange(disagreement_figure, linear_predict_plot)
#library(gridExtra)
#grid.arrange(disagreement_figure, linear_predict_plot)
plot_grid(disagreement_figure, linear_predict_plot)
#library(gridExtra)
#grid.arrange(disagreement_figure, linear_predict_plot)
library(cowplot)
plot_grid(disagreement_figure, linear_predict_plot)
#library(gridExtra)
#grid.arrange(disagreement_figure, linear_predict_plot)
library(cowplot)
plot_grid(disagreement_figure, linear_predict_plot)
library(tidyverse)        # ggplot, dplyr, %>%, and friends
library(brms)             # Bayesian modeling through Stan
library(tidybayes)        # Manipulate Stan objects in a tidy way
library(bayestestR)
library(broom)            # Convert model objects to data frames
library(broom.mixed)      # Convert brms model objects to data frames
library(betareg)          # Run beta regression models
library(ordbetareg)       # For running ordered beta regression
library(extraDistr)       # Use extra distributions like dprop()
library(ggdist)           # Special geoms for posterior distributions
library(gghalves)         # Special half geoms
library(ggbeeswarm)       # Special distribution-shaped point jittering
library(ggrepel)          # Automatically position labels
library(patchwork)        # Combine ggplot objects
library(marginaleffects)  # Calculate marginal effects for frequentist models
library(emmeans)          # Calculate marginal effects in even fancier ways
library(modelsummary)     # Create side-by-side regression tables
library(modelr)
library(lmtest)           # some nice functions for vetting linear models
library(knitr)
library(kableExtra)
library(data.table)
library(ggplot2)
library(hablar)
library(rstanarm)
library(loo)
library(cowplot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# beta regression can't handle 0's or 1's
fake_altered_data = data %>%
mutate(disagreement = ifelse(disagreement == 0, 0.001, disagreement)) %>%
mutate(disagreement = ifelse(disagreement == 1, 0.999, disagreement))
# beta regression, which can only run on fake data
output = capture.output(beta_model <- brm(
bf(disagreement ~ divergence + change + confidence + importance + belief_strength + same_side,
phi ~ divergence + change + confidence + importance + belief_strength + same_side),
data = fake_altered_data,
family = Beta(),
chains = 6, iter = 3000, warmup = 2000,
cores = 6, seed = 1234,
backend = "cmdstanr"
))
# we can add the `loo` criterion for model fitting later
beta_model = add_criterion(beta_model, 'loo', 'waic')
plot(beta_model)
kable(tidy(beta_model))
# check the Rhat values
kable(diagnostic_posterior(beta_model), digits=3)
pp_check(beta_model)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
beta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),10000),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
beta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction, color="red")) +
theme_classic(base_size = 15) +
geom_point(alpha=0.3, size=3) +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, beta_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
beta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),10000),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
beta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction, color="red")) +
theme_classic(base_size = 15) +
geom_point(alpha=0.03, size=3) +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, beta_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
beta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
beta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction, color="red")) +
theme_classic(base_size = 15) +
geom_point(alpha=0.1, size=3) +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, beta_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
beta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
beta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction, color="red")) +
theme_classic(base_size = 15) +
geom_point(alpha=0.1, size=3) +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, beta_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
beta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
beta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction, color="red")) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3) +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, beta_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
beta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
beta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3,  color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, beta_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
linear_predictions = predicted_draws(linear_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
linear_predictions_subset = linear_predictions[sample(nrow(linear_predictions),10000),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
linear_predict_plot = ggplot(linear_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=0.1, size=3, color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from linear model')
plot_grid(disagreement_figure, linear_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
linear_predictions = predicted_draws(linear_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
linear_predictions_subset = linear_predictions[sample(nrow(linear_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
linear_predict_plot = ggplot(linear_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=0.1, size=3, color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from linear model')
plot_grid(disagreement_figure, linear_predict_plot)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
linear_predictions = predicted_draws(linear_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
linear_predictions_subset = linear_predictions[sample(nrow(linear_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
linear_predict_plot = ggplot(linear_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3, color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from linear model')
plot_grid(disagreement_figure, linear_predict_plot)
# read in the data
data = read.csv(file = 'ord_bet_reg_data.csv')
# make a simple plot the depicts what we are interested in
disagreement_figure = ggplot(data, aes(x=divergence, y=disagreement)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3, color='aliceblue') +
labs(y = 'Disagreement', x = 'Difference in beliefs') +
scale_fill_brewer(palette = 'Dark2') +
#facet_wrap(~ importance_binarized) +
ggtitle('Actual data')
disagreement_figure
# read in the data
data = read.csv(file = 'ord_bet_reg_data.csv')
# make a simple plot the depicts what we are interested in
disagreement_figure = ggplot(data, aes(x=divergence, y=disagreement)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3, color='cadetblue') +
labs(y = 'Disagreement', x = 'Difference in beliefs') +
scale_fill_brewer(palette = 'Dark2') +
#facet_wrap(~ importance_binarized) +
ggtitle('Actual data')
disagreement_figure
# generate a data frame of new predicted values from the data that we already have. does it even do well?
beta_predictions = predicted_draws(beta_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
beta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
beta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3,  color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, beta_predict_plot)
# zoib model
output = capture.output(zoib_model <- brm(
bf(
disagreement ~ divergence + change + confidence + importance + belief_strength + same_side,
phi ~ divergence + change + confidence + importance + belief_strength + same_side,
zoi ~ 1,
coi ~ 1
),
data = data,
family = zero_one_inflated_beta(),
chains = 6, iter = 3000, warmup = 2000,
cores = 6, seed = 1234,
backend = "cmdstanr"
))
# we can add the `loo` criterion for model fitting later
zoib_model = add_criterion(zoib_model, 'loo', 'waic')
# generate a data frame of new predicted values from the data that we already have. does it even do well?
zoib_predictions = predicted_draws(zoib_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
zoib_predictions_subset = zoib_predictions[sample(nrow(zoib_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
zoib_predict_plot = ggplot(zoib_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3,  color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, zoib_predict_plot)
ordered_beta_reg = ordbetareg(
formula = disagreement ~ divergence + belief_strength + importance + confidence + change + same_side,
data = data,
chains = 6, iter = 3000, warmup = 2000,
cores = 6, seed = 1234,
)
# we can add the `loo` criterion for model fitting later
ordered_beta_reg = add_criterion(ordered_beta_reg, 'loo', 'waic')
# generate a data frame of new predicted values from the data that we already have. does it even do well?
ord_beta_predictions = predicted_draws(ordered_beta_reg, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
ord_beta_predictions_subset = ord_beta_predictions[sample(nrow(ord_beta_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
ord_beta_predict_plot = ggplot(ord_beta_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3,  color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, ord_beta_predict_plot)
output = capture.output(ordered_beta_reg = ordbetareg(
formula = disagreement ~ divergence + belief_strength + importance + confidence + change + same_side,
data = data,
chains = 6, iter = 3000, warmup = 2000,
cores = 6, seed = 1234,
))
# apologies for the long output. attempts to hide were unsuccessful
output = capture.output(ordered_beta_reg = ordbetareg(
formula = disagreement ~ divergence + belief_strength + importance + confidence + change + same_side,
data = data,
chains = 6, iter = 3000, warmup = 2000,
cores = 6, seed = 1234,
))
# we can add the `loo` criterion for model fitting later
ordered_beta_reg = add_criterion(ordered_beta_reg, 'loo', 'waic')
loo_cmp = loo_compare(linear_model,beta_model,zoib_model)
# create a data frame to store the LOO compare result
df_loo_cmp <- data.frame(
Model = c("Model 1", "Model 2","Model 3"),
LOOIC = c(loo_cmp[1,1], loo_cmp[2,1], loo_cmp[3,1]),
SE = c(loo_cmp[1,2], loo_cmp[2,2], loo_cmp[3,2])
)
# create the barplot
ggplot(df_loo_cmp, aes(x = Model, y = LOOIC, fill = Model)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = LOOIC - 1.96*SE, ymax = LOOIC + 1.96*SE), width = 0.2) +
labs(x = "", y = "LOOIC") +
theme_classic() +
theme(legend.position = "none")
loo_cmp = loo_compare(linear_model,beta_model,zoib_model, ordered_beta_reg)
# create a data frame to store the LOO compare result
df_loo_cmp <- data.frame(
Model = c("Linear", "Beta Reg","ZOIB","Ordered Beta Reg"),
LOOIC = c(loo_cmp[1,1], loo_cmp[2,1], loo_cmp[3,1], loo_cmp[4,1]),
SE = c(loo_cmp[1,2], loo_cmp[2,2], loo_cmp[3,2], loo_cmp[4,2])
)
# create the barplot
ggplot(df_loo_cmp, aes(x = Model, y = LOOIC, fill = Model)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin = LOOIC - 1.96*SE, ymax = LOOIC + 1.96*SE), width = 0.2) +
labs(x = "", y = "LOOIC") +
theme_classic() +
theme(legend.position = "none")
loo_cmp = loo_compare(linear_model,beta_model,zoib_model, ordered_beta_reg)
# create a data frame to store the LOO compare result
df_loo_cmp <- data.frame(
Model = c("Linear", "Beta Reg","ZOIB","Ordered Beta Reg"),
LOOIC = c(loo_cmp[1,1], loo_cmp[2,1], loo_cmp[3,1], loo_cmp[4,1]),
SE = c(loo_cmp[1,2], loo_cmp[2,2], loo_cmp[3,2], loo_cmp[4,2])
)
# create the barplot
ggplot(df_loo_cmp, aes(x = Model, y = LOOIC, fill = Model)) +
geom_bar(stat = "identity") +
#geom_errorbar(aes(ymin = LOOIC - 1.96*SE, ymax = LOOIC + 1.96*SE), width = 0.2) +
labs(x = "", y = "LOOIC") +
theme_classic() +
theme(legend.position = "none")
loo_cmp = loo_compare(linear_model,beta_model,zoib_model, ordered_beta_reg)
# create a data frame to store the LOO compare result
df_loo_cmp <- data.frame(
Model = c("Linear", "Beta Reg","ZOIB","Ordered Beta Reg"),
LOOIC = c(loo_cmp[1,1], loo_cmp[2,1], loo_cmp[3,1], loo_cmp[4,1]),
SE = c(loo_cmp[1,2], loo_cmp[2,2], loo_cmp[3,2], loo_cmp[4,2])
)
# create the barplot
ggplot(df_loo_cmp, aes(x = factor(Model, level=c('Linear','Beta Reg','ZOIB','Ordered Beta Reg')), y = LOOIC, fill = Model)) +
geom_bar(stat = "identity") +
#geom_errorbar(aes(ymin = LOOIC - 1.96*SE, ymax = LOOIC + 1.96*SE), width = 0.2) +
labs(x = "", y = "LOOIC") +
theme_classic() +
theme(legend.position = "none")
# apologies for the long output. attempts to hide were unsuccessful
ordered_beta_reg = ordbetareg(
formula = disagreement ~ divergence + belief_strength + importance + confidence + change + same_side,
data = data,
chains = 6, iter = 3000, warmup = 2000,
cores = 6, seed = 1234,
)
# we can add the `loo` criterion for model fitting later
ordered_beta_reg = add_criterion(ordered_beta_reg, 'loo', 'waic')
plot(ordered_beta_reg)
kable(tidy(ordered_beta_reg))
# check the Rhat values
kable(diagnostic_posterior(ordered_beta_reg), digits=3)
pp_check(ordered_beta_reg)
# generate a data frame of new predicted values from the data that we already have. does it even do well?
ord_beta_predictions = predicted_draws(ordered_beta_reg, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
ord_beta_predictions_subset = ord_beta_predictions[sample(nrow(ord_beta_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
ord_beta_predict_plot = ggplot(ord_beta_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3,  color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from beta regression')
plot_grid(disagreement_figure, ord_beta_predict_plot)
# generate a data frame of new predicted values from the data that we already have. Does it even do well?
linear_predictions = predicted_draws(linear_model, newdata=data)
# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set
linear_predictions_subset = linear_predictions[sample(nrow(linear_predictions),500),]
# plot the predicted data
# Plot disagreement vs Belief Divergence
linear_predict_plot = ggplot(linear_predictions_subset, aes(x=divergence, y=.prediction)) +
theme_classic(base_size = 15) +
geom_point(alpha=1, size=3, color="pink") +
labs(y = 'Disagreement', x = 'Belief Difference') +
scale_fill_brewer(palette = 'Dark2') +
ggtitle('Simulated data from linear model')
plot_grid(disagreement_figure, linear_predict_plot)
tidy(zoib_model)
summary(zoib_model)
tidy(summary(zoib_model))
summary(zoib_model)
kable(summary(zoib_model))
summary(zoib_model)
# check the Rhat values
kable(diagnostic_posterior(zoib_model), digits=3)
pp_check(zoib_model)
summary(ordered_beta_reg)
# check the Rhat values
kable(diagnostic_posterior(ordered_beta_reg), digits=3)
pp_check(ordered_beta_reg)
loo_cmp = loo_compare(linear_model,beta_model,zoib_model, ordered_beta_reg)
# create a data frame to store the LOO compare result
df_loo_cmp <- data.frame(
Model = c("Linear", "Beta Reg","ZOIB","Ordered Beta Reg"),
LOOIC = c(loo_cmp[1,1], loo_cmp[2,1], loo_cmp[3,1], loo_cmp[4,1]),
SE = c(loo_cmp[1,2], loo_cmp[2,2], loo_cmp[3,2], loo_cmp[4,2])
)
# create the barplot
ggplot(df_loo_cmp, aes(x = factor(Model, level=c('Linear','Beta Reg','ZOIB','Ordered Beta Reg')), y = LOOIC, fill = Model)) +
geom_bar(stat = "identity") +
#geom_errorbar(aes(ymin = LOOIC - 1.96*SE, ymax = LOOIC + 1.96*SE), width = 0.2) +
labs(x = "", y = "LOOIC") +
theme_classic() +
theme(legend.position = "none") +
labs(title="Formal Model Comparison. More negative is better.")
