{
  "hash": "5fb15fda996b31feefa3f090a118c8cb",
  "result": {
    "markdown": "---\ntitle: \"Ordered Beta Regression and Other Models\"\nauthor: \"J. Branson Byers\"\ndate: \"2023-02-01\"\ncategories: [news, code, analysis]\n---\n\n\n\n\n\n\n# Introduction\n\nIn psychology research, it is common to come across data sets that are comprised of continuous responses on a finite scale. When it comes time to making claims about that data, scientists often default to Ordinary Least Squares Regression. Let's take a dataset of precisely this kind of data: continuous, bounded responses from humans, and see how different models perform. We will note some flaws of these models, and demonstrate the benefits of some of the newer, more advanced models being used today. We make the case that for any kind of bounded, continuous data, Ordered Beta Regression should be used since it is a more general and sparse model than other good alternatives.\n\n## The Data\n\nThe data that we examine here is an approximated version of an unpublished data set regarding disagreement. Let's load in our data, and take a look at what we are working with.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# read in the data\ndata = read.csv(file = 'ord_bet_reg_data.csv')\n\n# make a simple plot the depicts what we are interested in\ndisagreement_figure = ggplot(data, aes(x=divergence, y=disagreement)) + \n  theme_classic(base_size = 15) + \n  geom_point(alpha=1, size=3, color='cadetblue') + \n  labs(y = 'Disagreement', x = 'Difference in beliefs') +\n  scale_fill_brewer(palette = 'Dark2') +\n  #facet_wrap(~ importance_binarized) +\n  ggtitle('Actual data')\n\ndisagreement_figure\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nWhat we see here is a roughly positive trend in the data, with a decent amount of data appearing at the bounds of zero and one. Is there a way we could quantify both this positive relationship the capture how the data gathers at the bounds?\n\n# Simulation of data with a model menagerie\n\n## Linear Model\n\nIt is common for psychologists to use frequentist models in their work. As of late, many are turning to Bayesian approaches. One large upside of using a Bayesian approach is that one can get an estimate of how certain the estimates within one's model are. Another upside, is that Bayesian methods provide a robust way conducting model comparison, which can offer a rigorous way of testing hypotheses about the form one one's data.\n\n::: panel-tabset\n### Model Specification\n\nFor now, we don't go into the details about each of the regressors. What matters here is whether or not a linear model can capture the features of the data that we care about.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# linear model\noutput = capture.output(linear_model <- brm(\n  formula = disagreement ~ divergence + change + confidence + importance + belief_strength + same_side,\n  data = data,\n  chains = 6, iter = 3000, warmup = 2000,\n  cores = 6, seed = 1234, \n  backend = \"cmdstanr\"\n))\n\n# we can add the `loo` criterion for model comparison later\nlinear_model = add_criterion(linear_model, 'loo',\"waic\")\n```\n:::\n\n\n### Model Convergence\n\nWe can see that our parameters are relatively smoothly Gaussian, and that the chains are intermingled like a \"fuzzy caterpillar.\" This means that our software is converging, which is good.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(linear_model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=90%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-2.png){fig-align='center' width=90%}\n:::\n:::\n\n\n### Results\n\nIn case one is curious about the exact numerical estimates within the model. These are not of concern to us right now.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkable(tidy(linear_model))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> effect </th>\n   <th style=\"text-align:left;\"> component </th>\n   <th style=\"text-align:left;\"> group </th>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 0.42 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> 0.31 </td>\n   <td style=\"text-align:right;\"> 0.52 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> divergence </td>\n   <td style=\"text-align:right;\"> 0.72 </td>\n   <td style=\"text-align:right;\"> 0.06 </td>\n   <td style=\"text-align:right;\"> 0.61 </td>\n   <td style=\"text-align:right;\"> 0.84 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> change </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> -0.08 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> confidence </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> 0.05 </td>\n   <td style=\"text-align:right;\"> -0.10 </td>\n   <td style=\"text-align:right;\"> 0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> importance </td>\n   <td style=\"text-align:right;\"> 0.02 </td>\n   <td style=\"text-align:right;\"> 0.04 </td>\n   <td style=\"text-align:right;\"> -0.05 </td>\n   <td style=\"text-align:right;\"> 0.10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> belief_strength </td>\n   <td style=\"text-align:right;\"> -0.24 </td>\n   <td style=\"text-align:right;\"> 0.07 </td>\n   <td style=\"text-align:right;\"> -0.38 </td>\n   <td style=\"text-align:right;\"> -0.11 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NA </td>\n   <td style=\"text-align:left;\"> same_sideTRUE </td>\n   <td style=\"text-align:right;\"> -0.15 </td>\n   <td style=\"text-align:right;\"> 0.03 </td>\n   <td style=\"text-align:right;\"> -0.21 </td>\n   <td style=\"text-align:right;\"> -0.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ran_pars </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> Residual </td>\n   <td style=\"text-align:left;\"> sd__Observation </td>\n   <td style=\"text-align:right;\"> 0.21 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n   <td style=\"text-align:right;\"> 0.20 </td>\n   <td style=\"text-align:right;\"> 0.23 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Other Diagnostics\n\nRhat should be exactly 1, which it is. Another indicator that our model has converged.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# check the Rhat values\nkable(diagnostic_posterior(linear_model), digits=3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Parameter </th>\n   <th style=\"text-align:right;\"> Rhat </th>\n   <th style=\"text-align:right;\"> ESS </th>\n   <th style=\"text-align:right;\"> MCSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> b_belief_strength </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 4924 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_change </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5911 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_confidence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 4945 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_divergence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 3807 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_importance </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5765 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 4942 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_same_sideTRUE </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 4200 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Posterior Predictive Check\n\nWe will discuss this more below, but it looks like there is some kind of systematic error between the predictions that our model is making and the actual data. Why might this be?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(linear_model)\n## Using 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=90%}\n:::\n:::\n\n:::\n\nAfter clicking through the tabs above, we can see that our model did indeed converge, and is giving us estimates for how each predictor influences disagreement judgements. But before we go through the work of interpreting these results, we ask ourselves, are we even using the right model? If we look at our posterior predictive checks above, we can see that something is amiss.\n\nWe can get a more intuitive sense of what is going wrong by using the samples generated from our MCMC sampler to simulate data. This allows us to visualize our data how our model sees our data.\n\n### Data Simulation\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# generate a data frame of new predicted values from the data that we already have. Does it even do well?\nlinear_predictions = predicted_draws(linear_model, newdata=data)\n\n# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set\nlinear_predictions_subset = linear_predictions[sample(nrow(linear_predictions),500),]\n\n# plot the predicted data\n# Plot disagreement vs Belief Divergence\nlinear_predict_plot = ggplot(linear_predictions_subset, aes(x=divergence, y=.prediction)) + \n  theme_classic(base_size = 15) + \n  geom_point(alpha=1, size=3, color=\"pink\") + \n  labs(y = 'Disagreement', x = 'Belief Difference') +\n  scale_fill_brewer(palette = 'Dark2') +\n  ggtitle('Linear Simulation')\n```\n:::\n\n\nWe can compare the simulated data to the actual data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_grid(disagreement_figure, linear_predict_plot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nWe can immediately identify some issues, but we can also glean some insights. The first large issue is that our model makes predictions that are outside the actual possible range in our data set. That it, people can only give disagreement rating between 0 and 1, and our model predicts that they might respond more or less than those upper and lower bounds. Our model also appears unable to capture the clustering at the bounds that we see in our actual data.\n\nWhat this tells us, is that this clustering effect at the bounds of disagreement ratings is not just due to how our data is sampled. That is, this clustering at the bounds actually tells us something about the functional form people might be using to make judgement about disagreement. Let's try another class of model, to see if it is able to better capture the interesting trends in our data.\n\n## Beta Regression\n\nIn order to improve our model's capability of representing the data and its actual bounds, we turn to beta regression. The beta distribution is incredibly flexible since is able to take on many different shapes with different amounts of variance. It is also bounded between zero and one. However, this boundedness comes with a large asterisk. The beta distribution is bounded between zero and one exclusive of zero and one. That means that we cannot accurately model data at the bounds without making some kind of modification to the data. And these might be exactly the points that we care about! Perhaps our research question asks how willing people are to completely agree or disagree.\n\nSince we are specifically interested in this behavior at the bounds of our data, we already know the beta distribution will be unable to actually model the phenomenon that we are interested in. Below, we slightly squeeze our data to allow us to run this model in the first place. We take a look at what kind of predictions this model makes, because we will build upon it to make improved models.\n\n::: panel-tabset\n### Model Specification\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n\n# beta regression can't handle 0's or 1's\nfake_altered_data = data %>% \n  mutate(disagreement = ifelse(disagreement == 0, 0.001, disagreement)) %>%\n  mutate(disagreement = ifelse(disagreement == 1, 0.999, disagreement))\n\n# beta regression, which can only run on fake data\noutput = capture.output(beta_model <- brm(\n  bf(disagreement ~ divergence + change + confidence + importance + belief_strength + same_side,\n     phi ~ divergence + change + confidence + importance + belief_strength + same_side),\n  data = fake_altered_data,\n  family = Beta(),\n  chains = 6, iter = 3000, warmup = 2000,\n  cores = 6, seed = 1234, \n  backend = \"cmdstanr\"\n))\n\n# we can add the `loo` criterion for model fitting later\nbeta_model = add_criterion(beta_model, 'loo', 'waic')\n```\n:::\n\n\n### Model Convergence\n\nLooks like our model converges just fine.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(beta_model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=90%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-2.png){fig-align='center' width=90%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-3.png){fig-align='center' width=90%}\n:::\n:::\n\n\n### Results\n\nFor those who might like to peek at this.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nkable(tidy(beta_model))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> effect </th>\n   <th style=\"text-align:left;\"> component </th>\n   <th style=\"text-align:left;\"> group </th>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.15 </td>\n   <td style=\"text-align:right;\"> 0.29 </td>\n   <td style=\"text-align:right;\"> -0.71 </td>\n   <td style=\"text-align:right;\"> 0.43 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.14 </td>\n   <td style=\"text-align:right;\"> 0.30 </td>\n   <td style=\"text-align:right;\"> -0.75 </td>\n   <td style=\"text-align:right;\"> 0.44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> 3.05 </td>\n   <td style=\"text-align:right;\"> 0.33 </td>\n   <td style=\"text-align:right;\"> 2.41 </td>\n   <td style=\"text-align:right;\"> 3.69 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.17 </td>\n   <td style=\"text-align:right;\"> 0.18 </td>\n   <td style=\"text-align:right;\"> -0.52 </td>\n   <td style=\"text-align:right;\"> 0.19 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.10 </td>\n   <td style=\"text-align:right;\"> 0.26 </td>\n   <td style=\"text-align:right;\"> -0.61 </td>\n   <td style=\"text-align:right;\"> 0.42 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.01 </td>\n   <td style=\"text-align:right;\"> 0.18 </td>\n   <td style=\"text-align:right;\"> -0.36 </td>\n   <td style=\"text-align:right;\"> 0.37 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.81 </td>\n   <td style=\"text-align:right;\"> 0.36 </td>\n   <td style=\"text-align:right;\"> -1.50 </td>\n   <td style=\"text-align:right;\"> -0.10 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.64 </td>\n   <td style=\"text-align:right;\"> 0.15 </td>\n   <td style=\"text-align:right;\"> -0.94 </td>\n   <td style=\"text-align:right;\"> -0.34 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> 0.26 </td>\n   <td style=\"text-align:right;\"> 0.35 </td>\n   <td style=\"text-align:right;\"> -0.43 </td>\n   <td style=\"text-align:right;\"> 0.94 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> 0.25 </td>\n   <td style=\"text-align:right;\"> 0.20 </td>\n   <td style=\"text-align:right;\"> -0.14 </td>\n   <td style=\"text-align:right;\"> 0.63 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> 0.77 </td>\n   <td style=\"text-align:right;\"> 0.26 </td>\n   <td style=\"text-align:right;\"> 0.27 </td>\n   <td style=\"text-align:right;\"> 1.29 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> -0.34 </td>\n   <td style=\"text-align:right;\"> 0.18 </td>\n   <td style=\"text-align:right;\"> -0.68 </td>\n   <td style=\"text-align:right;\"> 0.01 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> 0.86 </td>\n   <td style=\"text-align:right;\"> 0.37 </td>\n   <td style=\"text-align:right;\"> 0.13 </td>\n   <td style=\"text-align:right;\"> 1.60 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> fixed </td>\n   <td style=\"text-align:left;\"> cond </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:left;\"> NULL </td>\n   <td style=\"text-align:right;\"> 0.16 </td>\n   <td style=\"text-align:right;\"> 0.16 </td>\n   <td style=\"text-align:right;\"> -0.14 </td>\n   <td style=\"text-align:right;\"> 0.47 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Other Diagnostics\n\nConvergence confirmed.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# check the Rhat values\nkable(diagnostic_posterior(beta_model), digits=3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Parameter </th>\n   <th style=\"text-align:right;\"> Rhat </th>\n   <th style=\"text-align:right;\"> ESS </th>\n   <th style=\"text-align:right;\"> MCSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> b_belief_strength </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7598 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_change </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7786 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_confidence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7475 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_divergence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5949 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_importance </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7937 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7070 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_belief_strength </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6784 </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_change </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7828 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_confidence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7515 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_divergence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6298 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_importance </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 8394 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7107 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_same_sideTRUE </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6659 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_same_sideTRUE </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6437 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Posterior Predictive Check\n\nWe are generally getting the shape right here.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(beta_model)\n## Using 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=90%}\n:::\n:::\n\n:::\n\n### Data Simulation\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# generate a data frame of new predicted values from the data that we already have. does it even do well?\nbeta_predictions = predicted_draws(beta_model, newdata=data)\n\n# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set\nbeta_predictions_subset = beta_predictions[sample(nrow(beta_predictions),500),]\n\n# plot the predicted data\n# Plot disagreement vs Belief Divergence\nbeta_predict_plot = ggplot(beta_predictions_subset, aes(x=divergence, y=.prediction)) + \n  theme_classic(base_size = 15) + \n  geom_point(alpha=1, size=3,  color=\"pink\") + \n  labs(y = 'Disagreement', x = 'Belief Difference') +\n  scale_fill_brewer(palette = 'Dark2') +\n  ggtitle('Beta Regression Simulation')\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_grid(disagreement_figure, beta_predict_plot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nInterestingly, a Beta Distribution is able to capture our data quite well. We see a degree of clustering at the upper and lower ends of the belief difference spectrum, though it does not hit the bounds as we well know. A consequence of this we can see is that our simulated data is noisier than our original data. The Beta Distribution alone is not able to understand that a phenomenon at the bounds might be different than one not at the bounds. Let's move to a model that takes these two different processes into account.\n\n## Zero-One Inflated Beta Regression\n\nZero-One Inflated Beta Regression (ZOIB) is essentially a logistic regression and a beta regression meshed together. One parameter determines the likelihood that data will be generated by the logistic regression or the beta regression. The other parameters dictate the form of the Beta and Logistic regression separately. As a result of this, this model has many parameters. We do not show it here, but our model struggles to converge if we regress all of our predictors onto each parameter.\n\nThis is the price we pay for a more complex model. We see how well this model might perform, and then will ask, is there a way of achieving all the properties that we want in a model without introducing so many new parameters?\n\n::: panel-tabset\n### Model Specification\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n\n# zoib model\noutput = capture.output(zoib_model <- brm(\n  bf(\n    disagreement ~ divergence + change + confidence + importance + belief_strength + same_side,\n    phi ~ divergence + change + confidence + importance + belief_strength + same_side,\n    zoi ~ 1,\n    coi ~ 1\n     ),\n  data = data,\n  family = zero_one_inflated_beta(),\n  chains = 6, iter = 3000, warmup = 2000,\n  cores = 6, seed = 1234, \n  backend = \"cmdstanr\"\n))\n\n# we can add the `loo` criterion for model fitting later\nzoib_model = add_criterion(zoib_model, 'loo', 'waic')\n```\n:::\n\n\n### Model Convergence\n\nDespite having so many parameters, our model does indeed converge. This is likely because we have a relatively large data set of 500 samples.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(zoib_model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=90%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-2.png){fig-align='center' width=90%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-3.png){fig-align='center' width=90%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-4.png){fig-align='center' width=90%}\n:::\n:::\n\n\n### Results\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(zoib_model)\n##  Family: zero_one_inflated_beta \n##   Links: mu = logit; phi = log; zoi = logit; coi = logit \n## Formula: disagreement ~ divergence + change + confidence + importance + belief_strength + same_side \n##          phi ~ divergence + change + confidence + importance + belief_strength + same_side\n##          zoi ~ 1\n##          coi ~ 1\n##    Data: data (Number of observations: 500) \n##   Draws: 6 chains, each with iter = 3000; warmup = 2000; thin = 1;\n##          total post-warmup draws = 6000\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept              -0.58      0.23    -1.03    -0.14 1.00     7328     5145\n## phi_Intercept           1.84      0.36     1.15     2.56 1.00     6629     5038\n## zoi_Intercept          -1.79      0.13    -2.05    -1.55 1.00     8754     4624\n## coi_Intercept           1.14      0.27     0.63     1.68 1.00     8592     4224\n## divergence              3.24      0.27     2.71     3.79 1.00     6651     4807\n## change                 -0.10      0.15    -0.40     0.21 1.00     7529     4979\n## confidence             -0.13      0.22    -0.57     0.29 1.00     7027     4715\n## importance              0.40      0.17     0.06     0.73 1.00     7141     4721\n## belief_strength        -1.07      0.30    -1.66    -0.50 1.00     7073     4826\n## same_sideTRUE          -0.53      0.12    -0.77    -0.29 1.00     6547     4844\n## phi_divergence         -0.31      0.39    -1.06     0.46 1.00     6187     4773\n## phi_change              0.05      0.23    -0.41     0.51 1.00     7651     4788\n## phi_confidence         -0.24      0.33    -0.89     0.40 1.00     6666     4717\n## phi_importance          0.04      0.23    -0.42     0.49 1.00     6724     4796\n## phi_belief_strength     0.59      0.46    -0.31     1.47 1.00     7428     4799\n## phi_same_sideTRUE      -0.20      0.18    -0.55     0.16 1.00     6405     4765\n## \n## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\n### Other Diagnostics\n\nChecking for convergence and high effective sample size with a more complex model. ESS is well above 1000 for all parameters.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# check the Rhat values\nkable(diagnostic_posterior(zoib_model), digits=3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Parameter </th>\n   <th style=\"text-align:right;\"> Rhat </th>\n   <th style=\"text-align:right;\"> ESS </th>\n   <th style=\"text-align:right;\"> MCSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> b_belief_strength </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7037 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_change </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7488 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_coi_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 8480 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_confidence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7003 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_divergence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6638 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_importance </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7110 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7320 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_belief_strength </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7373 </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_change </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7528 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_confidence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6591 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_divergence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6146 </td>\n   <td style=\"text-align:right;\"> 0.005 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_importance </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6718 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6587 </td>\n   <td style=\"text-align:right;\"> 0.004 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_phi_same_sideTRUE </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6387 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_same_sideTRUE </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6469 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_zoi_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 8671 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Posterior Predictive Check\n\nWe are gaining some predictive power on the right side here in comparison to Beta Regression. Let's simulate data to see why we might be achieving these gains.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(zoib_model)\n## Using 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=90%}\n:::\n:::\n\n:::\n\n### Data Simulation\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# generate a data frame of new predicted values from the data that we already have. does it even do well?\nzoib_predictions = predicted_draws(zoib_model, newdata=data)\n\n# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set\nzoib_predictions_subset = zoib_predictions[sample(nrow(zoib_predictions),500),]\n\n# plot the predicted data\n# Plot disagreement vs Belief Divergence\nzoib_predict_plot = ggplot(zoib_predictions_subset, aes(x=divergence, y=.prediction)) + \n  theme_classic(base_size = 15) + \n  geom_point(alpha=1, size=3,  color=\"pink\") + \n  labs(y = 'Disagreement', x = 'Belief Difference') +\n  scale_fill_brewer(palette = 'Dark2') +\n  ggtitle('ZOIB Simulation')\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_grid(disagreement_figure, zoib_predict_plot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nAdmittedly this looks great. We are capturing the effects that we wanted at the bounds and elsewhere. Our models are converging, but as we noted, it is difficult for them to converge if all regressors are included. This is likely because our model is two models squashed together. Do we really need two models made into one to get the effect that we want?\n\n## Ordered Beta Regression\n\nWe suggest that Ordered Beta Regression is able to solve the problems with ZOIB. It is able to capture phenomena at the bounds of data without the number of parameters in the model exploding. It does this by introducing dependency between the likeliness of a data point being at the bounds of the data and how likely data points are to appear at the bounds as the dependent variable gets larger. This is done through two parameters in addition to the ones in a beta distribution referred to as cut points.\n\nThe analogy often used for understanding cut points is that in reality the phenomenon of interest is actually unbounded (like disagreement), but we cannot measure an unbounded phenomenon. We assume that if someone's preference is far above the bounds, they become increasingly likely to give a response at the upper bound (if it is above) and at the lower bound (if it is below).\n\nThe cuts down on the number of parameters needed to model the same kind of data as a ZOIB model.\n\n::: panel-tabset\n### Model Specification\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n\n# apologies for the long output. attempts to hide were unsuccessful\nordered_beta_reg = ordbetareg(\n  formula = disagreement ~ divergence + belief_strength + importance + confidence + change + same_side,\n  data = data,\n  chains = 6, iter = 3000, warmup = 2000,\n  cores = 6, seed = 1234, \n)\n## Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\n## clang -mmacosx-version-min=10.13 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DBOOST_NO_AUTO_PTR  -include '/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o\n## In file included from <built-in>:1:\n## In file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\n## In file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\n## In file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:88:\n## /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\n## namespace Eigen {\n## ^\n## /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\n## namespace Eigen {\n##                ^\n##                ;\n## In file included from <built-in>:1:\n## In file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/mat/fun/Eigen.hpp:13:\n## In file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\n## /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n## #include <complex>\n##          ^~~~~~~~~\n## 3 errors generated.\n## make: *** [foo.o] Error 1\n\n# we can add the `loo` criterion for model fitting later\nordered_beta_reg = add_criterion(ordered_beta_reg, 'loo', 'waic')\n```\n:::\n\n\n### Model Convergence\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(ordered_beta_reg)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=90%}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-2.png){fig-align='center' width=90%}\n:::\n:::\n\n\n### Results\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(ordered_beta_reg)\n##  Family: ord_beta_reg \n##   Links: mu = identity; phi = identity; cutzero = identity; cutone = identity \n## Formula: disagreement ~ divergence + belief_strength + importance + confidence + change + same_side \n##    Data: data (Number of observations: 500) \n##   Draws: 6 chains, each with iter = 3000; warmup = 2000; thin = 1;\n##          total post-warmup draws = 6000\n## \n## Population-Level Effects: \n##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept          -0.50      0.21    -0.92    -0.07 1.00     6319     4412\n## divergence          3.20      0.25     2.72     3.70 1.00     5671     4328\n## belief_strength    -1.02      0.27    -1.55    -0.48 1.00     7180     4966\n## importance          0.34      0.15     0.03     0.64 1.00     7563     4466\n## confidence         -0.18      0.20    -0.57     0.23 1.00     6841     4138\n## change             -0.15      0.14    -0.43     0.13 1.00     6908     3934\n## same_sideTRUE      -0.53      0.11    -0.75    -0.31 1.00     6451     4430\n## \n## Family Specific Parameters: \n##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## phi         5.33      0.35     4.67     6.04 1.00     7875     4671\n## cutzero    -3.59      0.25    -4.09    -3.11 1.00     6054     4119\n## cutone      1.83      0.05     1.73     1.92 1.00     6042     4542\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\n### Other Diagnostics\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# check the Rhat values\nkable(diagnostic_posterior(ordered_beta_reg), digits=3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Parameter </th>\n   <th style=\"text-align:right;\"> Rhat </th>\n   <th style=\"text-align:right;\"> ESS </th>\n   <th style=\"text-align:right;\"> MCSE </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> b_belief_strength </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7123 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_change </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6785 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_confidence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6883 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_divergence </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 5616 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_importance </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 7495 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_Intercept </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6282 </td>\n   <td style=\"text-align:right;\"> 0.003 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> b_same_sideTRUE </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 6443 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Posterior Predictive Check\n\nWe nicely follow the predicted shape here.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npp_check(ordered_beta_reg)\n## Using 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){fig-align='center' width=90%}\n:::\n:::\n\n:::\n\n### Data Simulation\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# generate a data frame of new predicted values from the data that we already have. does it even do well?\nord_beta_predictions = predicted_draws(ordered_beta_reg, newdata=data)\n\n# there are going to be an enormous number of these predictions, so let's thin them out randomly the idea is that we should still get proportional results to the full set\nord_beta_predictions_subset = ord_beta_predictions[sample(nrow(ord_beta_predictions),500),]\n\n# plot the predicted data\n# Plot disagreement vs Belief Divergence\nord_beta_predict_plot = ggplot(ord_beta_predictions_subset, aes(x=divergence, y=.prediction)) + \n  theme_classic(base_size = 15) + \n  geom_point(alpha=1, size=3,  color=\"pink\") + \n  labs(y = 'Disagreement', x = 'Belief Difference') +\n  scale_fill_brewer(palette = 'Dark2') +\n  ggtitle('Ordered Beta Simulation')\n```\n:::\n\n\nRecall that our actual data looks like this.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_grid(disagreement_figure, ord_beta_predict_plot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-29-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nVoila! A lower parameter method for capturing bounded data with phenomena at the bounds.\n\n# Formal model comparison\n\nIs decreasing the number of parameters really worth the trouble? And do our models actually fit our data better? The only way to actually answer this question is through formal model comparison.\n\nWe use an information criterion known as Leave-One-Out Validation. The idea here is that (1) a model should predict the data that is available with a high probability (2) the model should predict data it has never seen with high probability. How do we know how well the model predicts data that is has never seen? We make an approximation by fitting the model to all of the data, save on point, and see how well the model predict that single point. We then repeat this for every data point in the set.\n\nObviously, this can be quite computationally intensive. Some clever mathematicians came up with the LOO criterion which is a great, computationally efficient method for computing exactly what we need. The more negative the criterion, the better.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nloo_cmp = loo_compare(linear_model,beta_model,zoib_model, ordered_beta_reg)\n## Warning: Not all models have the same y variable. ('yhash' attributes do not match)\n\n# create a data frame to store the LOO compare result\ndf_loo_cmp <- data.frame(\n  Model = c(\"Linear\", \"Beta Reg\",\"ZOIB\",\"Ordered Beta Reg\"),\n  LOOIC = c(loo_cmp[1,1], loo_cmp[2,1], loo_cmp[3,1], loo_cmp[4,1]),\n  SE = c(loo_cmp[1,2], loo_cmp[2,2], loo_cmp[3,2], loo_cmp[4,2])\n)\n\n# create the barplot\nggplot(df_loo_cmp, aes(x = factor(Model, level=c('Linear','Beta Reg','ZOIB','Ordered Beta Reg')), y = LOOIC, fill = Model)) + \n  geom_bar(stat = \"identity\") +\n  #geom_errorbar(aes(ymin = LOOIC - 1.96*SE, ymax = LOOIC + 1.96*SE), width = 0.2) +\n  labs(x = \"\", y = \"LOOIC\") +\n  theme_classic() +\n  theme(legend.position = \"none\") +\n  labs(title=\"Formal Model Comparison. More negative is better.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-30-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\nWe see here exactly what we expected. By comparison, our Ordinary Least Squares model performs quite terribly. We see a drastic improvement when we move to Beta Regression (which technically is not even fit on the same data set), and gradual improvement from there to ZOIB and again to Ordered Beta Regression.\n\nThis is evidence that indeed, Ordered Beta Regression is worth the trouble of understanding and using, especially over linear models simply because of performance and predictive power. We also note that has a strict advantage over Beta Regression because it does not require modifying existing data in any way.\n\nFor more information about Ordered Beta Regression, one can read the formal publication here: <https://www.cambridge.org/core/journals/political-analysis/article/ordered-beta-regression-a-parsimonious-wellfitting-model-for-continuous-data-with-lower-and-upper-bounds/89F4141DA16D4FC217809B5EB45EEE83>\n\nFor more information about LOO, we recommend the following: <https://arxiv.org/abs/1507.04544>\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}